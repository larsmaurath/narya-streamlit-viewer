<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>narya.datasets.homography_dataset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>narya.datasets.homography_dataset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import mxnet as mx
import os
import cv2
import keras
import numpy as np
import keras.backend as K
from lxml import etree
import six
import albumentations as A
import tensorflow as tf

from albumentations import DualTransform

from ..utils.homography import (
    vertical_flip_homo,
    horizontal_flip_homo,
    get_four_corners,
    normalize_homo,
)
from ..preprocessing.image import _build_homo_preprocessing


def new_tf_targets(self):
    &#34;&#34;&#34;Adds a new object to Albumentations. Allows it to deal not only with:
        * Images
        * Boxes
        * Masks
        * Keypoints
    but also with custom object. In this case: homography.
    We will only need to define custom function ```python3 self.apply_to_object``` for each
    albumentations object we use.
    &#34;&#34;&#34;
    return {
        &#34;image&#34;: self.apply,
        &#34;homo&#34;: self.apply_to_homo,
        &#34;mask&#34;: self.apply_to_mask,
        &#34;bboxes&#34;: self.apply_to_bboxes,
    }


DualTransform.targets = property(new_tf_targets)


class HorizontalFlipWithHomo(A.HorizontalFlip):
    &#34;&#34;&#34;Class based of albumentations.HorizontalFlip, to allow it to deal with homographies.

    &#34;&#34;&#34;

    def apply_to_homo(self, homo, **params):
        return horizontal_flip_homo(homo, **params)


class Lambda(A.Lambda):
    &#34;&#34;&#34;Class based of albumentations.Lambda, to allow it to deal with homographies.

    &#34;&#34;&#34;

    def apply_to_homo(self, homo, **params):
        return homo


class RandomCropWithHomo(A.RandomCrop):
    &#34;&#34;&#34;Class based of albumentations.RandomCrop, to allow it to deal with homographies.

    &#34;&#34;&#34;

    def apply_to_homo(self, homo, **params):
        return homo


class Dataset:
    &#34;&#34;&#34;Class for an homography dataset. Allows to load pairs of image, homography, and
    apply random transformation to them.

    Arguments:
        images_dir: Path to the folder containing the images, in a &#39;.jpg&#39; format.
        homo_dir: Path to the folder containing the homographies, in a &#39;.npy&#39; format.
                    The homography must have the same name as the image they are linked to.
        augmentation: None if we don&#39;t apply random transformation. Else, a function to apply.
        preprocessing: None if we don&#39;t apply random preprocessing. Else, a function to apply.
    
    &#34;&#34;&#34;

    def __init__(self, images_dir, homo_dir, augmentation=None, preprocessing=None):
        self.ids = os.listdir(images_dir)
        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]
        self.homo_fps = [
            os.path.join(homo_dir, image_id.replace(&#34;.jpg&#34;, &#34;_homo.npy&#34;))
            for image_id in self.ids
        ]

        self.augmentation = augmentation
        self.preprocessing = preprocessing

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, i):

        # read data
        image = cv2.imread(self.images_fps[i])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (280, 280))
        homo = np.load(self.homo_fps[i])
        homo = homo[0] if len(homo.shape) &gt; 2 else homo

        # apply augmentations
        temp_homo_0 = homo[0][0]
        if self.augmentation:
            sample = self.augmentation(image=image, homo=homo)
            image, homo = sample[&#34;image&#34;], sample[&#34;homo&#34;]

        # apply preprocessing
        if self.preprocessing:
            sample = self.preprocessing(image=image)
            image = sample[&#34;image&#34;]

        homo = normalize_homo(homo)

        if temp_homo_0 != homo[0][0]:
            homo = get_four_corners(homo)[0]
            for i in range(4):
                homo[0][i] = -homo[0][i]
        else:
            homo = get_four_corners(homo)[0]
        return image, homo.flatten()


def get_training_augmentation():
    &#34;&#34;&#34;Builds random transformations we want to apply to our dataset.

    Arguments:
        
    Returns:
        A albumentation functions to pass our images to.
    Raises:

    &#34;&#34;&#34;
    train_transform = [
        HorizontalFlipWithHomo(p=0.5),
        A.IAAAdditiveGaussianNoise(p=0.2),
        A.augmentations.transforms.RandomShadow(
            shadow_roi=(0, 0.5, 1, 1),
            num_shadows_lower=1,
            num_shadows_upper=1,
            shadow_dimension=3,
            always_apply=False,
            p=0.5,
        ),
        A.OneOf([A.RandomBrightness(p=1),], p=0.3,),
        A.OneOf([A.Blur(blur_limit=3, p=1), A.MotionBlur(blur_limit=3, p=1),], p=0.3,),
        A.OneOf([A.RandomContrast(p=1), A.HueSaturationValue(p=1),], p=0.3,),
        RandomCropWithHomo(height=256, width=256, always_apply=True),
    ]
    return A.Compose(train_transform)


def get_validation_augmentation():
    &#34;&#34;&#34;Builds random transformations we want to apply to our dataset.

    Arguments:
        
    Returns:
        A albumentation functions to pass our images to.
    Raises:

    &#34;&#34;&#34;
    train_transform = [
        HorizontalFlipWithHomo(p=0.5),
        RandomCropWithHomo(height=256, width=256, always_apply=True),
    ]
    return A.Compose(train_transform)


def get_preprocessing(preprocessing_fn):
    &#34;&#34;&#34;Construct preprocessing transform
    
    Arguments:
        preprocessing_fn (callable): data normalization function 
            (can be specific for each pretrained neural network)
    Return:
        transform: albumentations.Compose
    Raises:
    &#34;&#34;&#34;

    _transform = [
        Lambda(name=&#34;homo_preprocessing&#34;, image=preprocessing_fn),
    ]
    return A.Compose(_transform)


class Dataloder(tf.keras.utils.Sequence):
    &#34;&#34;&#34;Load data from dataset and form batches
    
    Arguments:
        dataset: instance of Dataset class for image loading and preprocessing.
        batch_size: Integer number of images in batch.
        shuffle: Boolean, if `True` shuffle image indexes each epoch.
    &#34;&#34;&#34;

    def __init__(self, dataset, batch_size=1, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(dataset))

        self.on_epoch_end()

    def __getitem__(self, i):

        images = []
        homos = []
        # collect batch data
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            x_y = self.dataset[j]
            image = x_y[0]
            true_homo = x_y[1]
            images.append(image)
            homos.append(true_homo)

        batch_image = np.array(images)
        batch_true_homo = np.array(homos)

        return (batch_image, batch_true_homo)

    def __len__(self):
        &#34;&#34;&#34;Denotes the number of batches per epoch&#34;&#34;&#34;
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        &#34;&#34;&#34;Callback function to shuffle indexes each epoch&#34;&#34;&#34;
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)


class HomographyDatasetBuilder:
    &#34;&#34;&#34;Class for an homography dataset. Allows to load pairs of image, homography, and
    apply random transformation to them. Also loads the dataloader you can then pass to a keras model.

    Arguments:
        img_train_dir: Path to the folder containing the training images, in a &#39;.jpg&#39; format.
        img_test_dir: Path to the folder containing the testing images, in a &#39;.jpg&#39; format.
        homo_train_dir: Path to the folder containing the training homographies, in a &#39;.npy&#39; format.
                    The homography must have the same name as the image they are linked to.
        homo_test_dir: Path to the folder containing the testing homographies, in a &#39;.npy&#39; format.
                    The homography must have the same name as the image they are linked to.
        batch_size: Integer number of images in batch.
        preprocess_input: None, or a preprocessing function to apply on the images.
        shuffle: Boolean, if `True` shuffle image indexes each epoch.
    &#34;&#34;&#34;

    def __init__(
        self,
        img_train_dir,
        img_test_dir,
        homo_train_dir,
        homo_test_dir,
        batch_size,
        preprocess_input,
        shuffle=True,
    ):

        self.train_dataset = Dataset(
            img_train_dir,
            homo_train_dir,
            augmentation=get_training_augmentation(),
            preprocessing=get_preprocessing(preprocess_input),
        )

        self.valid_dataset = Dataset(
            img_test_dir,
            homo_test_dir,
            augmentation=get_validation_augmentation(),
            preprocessing=get_preprocessing(preprocess_input),
        )

        self.train_dataloader = Dataloder(
            self.train_dataset, batch_size=batch_size, shuffle=shuffle
        )
        self.valid_dataloader = Dataloder(
            self.valid_dataset, batch_size=1, shuffle=False
        )

    def _get_dataset(self):
        return self.train_dataset, self.valid_dataset

    def _get_dataloader(self):
        return self.train_dataloader, self.valid_dataloader</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="narya.datasets.homography_dataset.get_preprocessing"><code class="name flex">
<span>def <span class="ident">get_preprocessing</span></span>(<span>preprocessing_fn)</span>
</code></dt>
<dd>
<div class="desc"><p>Construct preprocessing transform</p>
<h2 id="arguments">Arguments</h2>
<p>preprocessing_fn (callable): data normalization function
(can be specific for each pretrained neural network)</p>
<h2 id="return">Return</h2>
<p>transform: albumentations.Compose
Raises:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_preprocessing(preprocessing_fn):
    &#34;&#34;&#34;Construct preprocessing transform
    
    Arguments:
        preprocessing_fn (callable): data normalization function 
            (can be specific for each pretrained neural network)
    Return:
        transform: albumentations.Compose
    Raises:
    &#34;&#34;&#34;

    _transform = [
        Lambda(name=&#34;homo_preprocessing&#34;, image=preprocessing_fn),
    ]
    return A.Compose(_transform)</code></pre>
</details>
</dd>
<dt id="narya.datasets.homography_dataset.get_training_augmentation"><code class="name flex">
<span>def <span class="ident">get_training_augmentation</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds random transformations we want to apply to our dataset.</p>
<h2 id="arguments">Arguments</h2>
<h2 id="returns">Returns</h2>
<p>A albumentation functions to pass our images to.
Raises:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_training_augmentation():
    &#34;&#34;&#34;Builds random transformations we want to apply to our dataset.

    Arguments:
        
    Returns:
        A albumentation functions to pass our images to.
    Raises:

    &#34;&#34;&#34;
    train_transform = [
        HorizontalFlipWithHomo(p=0.5),
        A.IAAAdditiveGaussianNoise(p=0.2),
        A.augmentations.transforms.RandomShadow(
            shadow_roi=(0, 0.5, 1, 1),
            num_shadows_lower=1,
            num_shadows_upper=1,
            shadow_dimension=3,
            always_apply=False,
            p=0.5,
        ),
        A.OneOf([A.RandomBrightness(p=1),], p=0.3,),
        A.OneOf([A.Blur(blur_limit=3, p=1), A.MotionBlur(blur_limit=3, p=1),], p=0.3,),
        A.OneOf([A.RandomContrast(p=1), A.HueSaturationValue(p=1),], p=0.3,),
        RandomCropWithHomo(height=256, width=256, always_apply=True),
    ]
    return A.Compose(train_transform)</code></pre>
</details>
</dd>
<dt id="narya.datasets.homography_dataset.get_validation_augmentation"><code class="name flex">
<span>def <span class="ident">get_validation_augmentation</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds random transformations we want to apply to our dataset.</p>
<h2 id="arguments">Arguments</h2>
<h2 id="returns">Returns</h2>
<p>A albumentation functions to pass our images to.
Raises:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_validation_augmentation():
    &#34;&#34;&#34;Builds random transformations we want to apply to our dataset.

    Arguments:
        
    Returns:
        A albumentation functions to pass our images to.
    Raises:

    &#34;&#34;&#34;
    train_transform = [
        HorizontalFlipWithHomo(p=0.5),
        RandomCropWithHomo(height=256, width=256, always_apply=True),
    ]
    return A.Compose(train_transform)</code></pre>
</details>
</dd>
<dt id="narya.datasets.homography_dataset.new_tf_targets"><code class="name flex">
<span>def <span class="ident">new_tf_targets</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a new object to Albumentations. Allows it to deal not only with:
* Images
* Boxes
* Masks
* Keypoints
but also with custom object. In this case: homography.
We will only need to define custom function <code>python3 self.apply_to_object</code> for each
albumentations object we use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_tf_targets(self):
    &#34;&#34;&#34;Adds a new object to Albumentations. Allows it to deal not only with:
        * Images
        * Boxes
        * Masks
        * Keypoints
    but also with custom object. In this case: homography.
    We will only need to define custom function ```python3 self.apply_to_object``` for each
    albumentations object we use.
    &#34;&#34;&#34;
    return {
        &#34;image&#34;: self.apply,
        &#34;homo&#34;: self.apply_to_homo,
        &#34;mask&#34;: self.apply_to_mask,
        &#34;bboxes&#34;: self.apply_to_bboxes,
    }</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="narya.datasets.homography_dataset.Dataloder"><code class="flex name class">
<span>class <span class="ident">Dataloder</span></span>
<span>(</span><span>dataset, batch_size=1, shuffle=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Load data from dataset and form batches</p>
<h2 id="arguments">Arguments</h2>
<p>dataset: instance of Dataset class for image loading and preprocessing.
batch_size: Integer number of images in batch.
shuffle: Boolean, if <code>True</code> shuffle image indexes each epoch.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataloder(tf.keras.utils.Sequence):
    &#34;&#34;&#34;Load data from dataset and form batches
    
    Arguments:
        dataset: instance of Dataset class for image loading and preprocessing.
        batch_size: Integer number of images in batch.
        shuffle: Boolean, if `True` shuffle image indexes each epoch.
    &#34;&#34;&#34;

    def __init__(self, dataset, batch_size=1, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(dataset))

        self.on_epoch_end()

    def __getitem__(self, i):

        images = []
        homos = []
        # collect batch data
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            x_y = self.dataset[j]
            image = x_y[0]
            true_homo = x_y[1]
            images.append(image)
            homos.append(true_homo)

        batch_image = np.array(images)
        batch_true_homo = np.array(homos)

        return (batch_image, batch_true_homo)

    def __len__(self):
        &#34;&#34;&#34;Denotes the number of batches per epoch&#34;&#34;&#34;
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        &#34;&#34;&#34;Callback function to shuffle indexes each epoch&#34;&#34;&#34;
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.utils.data_utils.Sequence</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="narya.datasets.homography_dataset.Dataloder.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Callback function to shuffle indexes each epoch</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self):
    &#34;&#34;&#34;Callback function to shuffle indexes each epoch&#34;&#34;&#34;
    if self.shuffle:
        self.indexes = np.random.permutation(self.indexes)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="narya.datasets.homography_dataset.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>images_dir, homo_dir, augmentation=None, preprocessing=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for an homography dataset. Allows to load pairs of image, homography, and
apply random transformation to them.</p>
<h2 id="arguments">Arguments</h2>
<p>images_dir: Path to the folder containing the images, in a '.jpg' format.
homo_dir: Path to the folder containing the homographies, in a '.npy' format.
The homography must have the same name as the image they are linked to.
augmentation: None if we don't apply random transformation. Else, a function to apply.
preprocessing: None if we don't apply random preprocessing. Else, a function to apply.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataset:
    &#34;&#34;&#34;Class for an homography dataset. Allows to load pairs of image, homography, and
    apply random transformation to them.

    Arguments:
        images_dir: Path to the folder containing the images, in a &#39;.jpg&#39; format.
        homo_dir: Path to the folder containing the homographies, in a &#39;.npy&#39; format.
                    The homography must have the same name as the image they are linked to.
        augmentation: None if we don&#39;t apply random transformation. Else, a function to apply.
        preprocessing: None if we don&#39;t apply random preprocessing. Else, a function to apply.
    
    &#34;&#34;&#34;

    def __init__(self, images_dir, homo_dir, augmentation=None, preprocessing=None):
        self.ids = os.listdir(images_dir)
        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]
        self.homo_fps = [
            os.path.join(homo_dir, image_id.replace(&#34;.jpg&#34;, &#34;_homo.npy&#34;))
            for image_id in self.ids
        ]

        self.augmentation = augmentation
        self.preprocessing = preprocessing

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, i):

        # read data
        image = cv2.imread(self.images_fps[i])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (280, 280))
        homo = np.load(self.homo_fps[i])
        homo = homo[0] if len(homo.shape) &gt; 2 else homo

        # apply augmentations
        temp_homo_0 = homo[0][0]
        if self.augmentation:
            sample = self.augmentation(image=image, homo=homo)
            image, homo = sample[&#34;image&#34;], sample[&#34;homo&#34;]

        # apply preprocessing
        if self.preprocessing:
            sample = self.preprocessing(image=image)
            image = sample[&#34;image&#34;]

        homo = normalize_homo(homo)

        if temp_homo_0 != homo[0][0]:
            homo = get_four_corners(homo)[0]
            for i in range(4):
                homo[0][i] = -homo[0][i]
        else:
            homo = get_four_corners(homo)[0]
        return image, homo.flatten()</code></pre>
</details>
</dd>
<dt id="narya.datasets.homography_dataset.HomographyDatasetBuilder"><code class="flex name class">
<span>class <span class="ident">HomographyDatasetBuilder</span></span>
<span>(</span><span>img_train_dir, img_test_dir, homo_train_dir, homo_test_dir, batch_size, preprocess_input, shuffle=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for an homography dataset. Allows to load pairs of image, homography, and
apply random transformation to them. Also loads the dataloader you can then pass to a keras model.</p>
<h2 id="arguments">Arguments</h2>
<p>img_train_dir: Path to the folder containing the training images, in a '.jpg' format.
img_test_dir: Path to the folder containing the testing images, in a '.jpg' format.
homo_train_dir: Path to the folder containing the training homographies, in a '.npy' format.
The homography must have the same name as the image they are linked to.
homo_test_dir: Path to the folder containing the testing homographies, in a '.npy' format.
The homography must have the same name as the image they are linked to.
batch_size: Integer number of images in batch.
preprocess_input: None, or a preprocessing function to apply on the images.
shuffle: Boolean, if <code>True</code> shuffle image indexes each epoch.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HomographyDatasetBuilder:
    &#34;&#34;&#34;Class for an homography dataset. Allows to load pairs of image, homography, and
    apply random transformation to them. Also loads the dataloader you can then pass to a keras model.

    Arguments:
        img_train_dir: Path to the folder containing the training images, in a &#39;.jpg&#39; format.
        img_test_dir: Path to the folder containing the testing images, in a &#39;.jpg&#39; format.
        homo_train_dir: Path to the folder containing the training homographies, in a &#39;.npy&#39; format.
                    The homography must have the same name as the image they are linked to.
        homo_test_dir: Path to the folder containing the testing homographies, in a &#39;.npy&#39; format.
                    The homography must have the same name as the image they are linked to.
        batch_size: Integer number of images in batch.
        preprocess_input: None, or a preprocessing function to apply on the images.
        shuffle: Boolean, if `True` shuffle image indexes each epoch.
    &#34;&#34;&#34;

    def __init__(
        self,
        img_train_dir,
        img_test_dir,
        homo_train_dir,
        homo_test_dir,
        batch_size,
        preprocess_input,
        shuffle=True,
    ):

        self.train_dataset = Dataset(
            img_train_dir,
            homo_train_dir,
            augmentation=get_training_augmentation(),
            preprocessing=get_preprocessing(preprocess_input),
        )

        self.valid_dataset = Dataset(
            img_test_dir,
            homo_test_dir,
            augmentation=get_validation_augmentation(),
            preprocessing=get_preprocessing(preprocess_input),
        )

        self.train_dataloader = Dataloder(
            self.train_dataset, batch_size=batch_size, shuffle=shuffle
        )
        self.valid_dataloader = Dataloder(
            self.valid_dataset, batch_size=1, shuffle=False
        )

    def _get_dataset(self):
        return self.train_dataset, self.valid_dataset

    def _get_dataloader(self):
        return self.train_dataloader, self.valid_dataloader</code></pre>
</details>
</dd>
<dt id="narya.datasets.homography_dataset.HorizontalFlipWithHomo"><code class="flex name class">
<span>class <span class="ident">HorizontalFlipWithHomo</span></span>
<span>(</span><span>always_apply=False, p=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>Class based of albumentations.HorizontalFlip, to allow it to deal with homographies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HorizontalFlipWithHomo(A.HorizontalFlip):
    &#34;&#34;&#34;Class based of albumentations.HorizontalFlip, to allow it to deal with homographies.

    &#34;&#34;&#34;

    def apply_to_homo(self, homo, **params):
        return horizontal_flip_homo(homo, **params)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>albumentations.augmentations.transforms.HorizontalFlip</li>
<li>albumentations.core.transforms_interface.DualTransform</li>
<li>albumentations.core.transforms_interface.BasicTransform</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="narya.datasets.homography_dataset.HorizontalFlipWithHomo.apply_to_homo"><code class="name flex">
<span>def <span class="ident">apply_to_homo</span></span>(<span>self, homo, **params)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_to_homo(self, homo, **params):
    return horizontal_flip_homo(homo, **params)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="narya.datasets.homography_dataset.Lambda"><code class="flex name class">
<span>class <span class="ident">Lambda</span></span>
<span>(</span><span>image=None, mask=None, keypoint=None, bbox=None, name=None, always_apply=False, p=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Class based of albumentations.Lambda, to allow it to deal with homographies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Lambda(A.Lambda):
    &#34;&#34;&#34;Class based of albumentations.Lambda, to allow it to deal with homographies.

    &#34;&#34;&#34;

    def apply_to_homo(self, homo, **params):
        return homo</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>albumentations.augmentations.transforms.Lambda</li>
<li>albumentations.core.transforms_interface.NoOp</li>
<li>albumentations.core.transforms_interface.DualTransform</li>
<li>albumentations.core.transforms_interface.BasicTransform</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="narya.datasets.homography_dataset.Lambda.apply_to_homo"><code class="name flex">
<span>def <span class="ident">apply_to_homo</span></span>(<span>self, homo, **params)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_to_homo(self, homo, **params):
    return homo</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="narya.datasets.homography_dataset.RandomCropWithHomo"><code class="flex name class">
<span>class <span class="ident">RandomCropWithHomo</span></span>
<span>(</span><span>height, width, always_apply=False, p=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Class based of albumentations.RandomCrop, to allow it to deal with homographies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RandomCropWithHomo(A.RandomCrop):
    &#34;&#34;&#34;Class based of albumentations.RandomCrop, to allow it to deal with homographies.

    &#34;&#34;&#34;

    def apply_to_homo(self, homo, **params):
        return homo</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>albumentations.augmentations.transforms.RandomCrop</li>
<li>albumentations.core.transforms_interface.DualTransform</li>
<li>albumentations.core.transforms_interface.BasicTransform</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="narya.datasets.homography_dataset.RandomCropWithHomo.apply_to_homo"><code class="name flex">
<span>def <span class="ident">apply_to_homo</span></span>(<span>self, homo, **params)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_to_homo(self, homo, **params):
    return homo</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="narya.datasets" href="index.html">narya.datasets</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="narya.datasets.homography_dataset.get_preprocessing" href="#narya.datasets.homography_dataset.get_preprocessing">get_preprocessing</a></code></li>
<li><code><a title="narya.datasets.homography_dataset.get_training_augmentation" href="#narya.datasets.homography_dataset.get_training_augmentation">get_training_augmentation</a></code></li>
<li><code><a title="narya.datasets.homography_dataset.get_validation_augmentation" href="#narya.datasets.homography_dataset.get_validation_augmentation">get_validation_augmentation</a></code></li>
<li><code><a title="narya.datasets.homography_dataset.new_tf_targets" href="#narya.datasets.homography_dataset.new_tf_targets">new_tf_targets</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="narya.datasets.homography_dataset.Dataloder" href="#narya.datasets.homography_dataset.Dataloder">Dataloder</a></code></h4>
<ul class="">
<li><code><a title="narya.datasets.homography_dataset.Dataloder.on_epoch_end" href="#narya.datasets.homography_dataset.Dataloder.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="narya.datasets.homography_dataset.Dataset" href="#narya.datasets.homography_dataset.Dataset">Dataset</a></code></h4>
</li>
<li>
<h4><code><a title="narya.datasets.homography_dataset.HomographyDatasetBuilder" href="#narya.datasets.homography_dataset.HomographyDatasetBuilder">HomographyDatasetBuilder</a></code></h4>
</li>
<li>
<h4><code><a title="narya.datasets.homography_dataset.HorizontalFlipWithHomo" href="#narya.datasets.homography_dataset.HorizontalFlipWithHomo">HorizontalFlipWithHomo</a></code></h4>
<ul class="">
<li><code><a title="narya.datasets.homography_dataset.HorizontalFlipWithHomo.apply_to_homo" href="#narya.datasets.homography_dataset.HorizontalFlipWithHomo.apply_to_homo">apply_to_homo</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="narya.datasets.homography_dataset.Lambda" href="#narya.datasets.homography_dataset.Lambda">Lambda</a></code></h4>
<ul class="">
<li><code><a title="narya.datasets.homography_dataset.Lambda.apply_to_homo" href="#narya.datasets.homography_dataset.Lambda.apply_to_homo">apply_to_homo</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="narya.datasets.homography_dataset.RandomCropWithHomo" href="#narya.datasets.homography_dataset.RandomCropWithHomo">RandomCropWithHomo</a></code></h4>
<ul class="">
<li><code><a title="narya.datasets.homography_dataset.RandomCropWithHomo.apply_to_homo" href="#narya.datasets.homography_dataset.RandomCropWithHomo.apply_to_homo">apply_to_homo</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>