<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>narya.datasets.tracking_dataset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>narya.datasets.tracking_dataset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import mxnet as mx
from mxnet import autograd
from mxnet import gluon

from gluoncv.data import VOCDetection
from gluoncv.data.transforms.presets.ssd import SSDDefaultTrainTransform
from gluoncv.data.transforms.presets.ssd import SSDDefaultValTransform
from gluoncv.data.batchify import Tuple, Stack, Pad

CLASSES = [&#34;ball&#34;, &#34;player&#34;]

&#34;&#34;&#34;
Checking with Mxnet if a GPU is available or not.
&#34;&#34;&#34;
try:
    a = mx.nd.zeros((1,), ctx=mx.gpu(0))
    ctx = [mx.gpu(0)]
except:
    ctx = [mx.cpu()]


class VOCFootball(VOCDetection):
    &#34;&#34;&#34;Class for a tracking dataset. Allows to load pairs of image, bouding boxes, and
    apply random transformation to them. The dataset is base on the gluoncv.data VOC format
    dataset. You can also easily write your own custom dataset if your data are in a COCO format.

    Arguments:
        root: Path to folder storing the dataset
        splits: List of tuples, list of combinations (type,name). e.g: (&#39;foot&#39;,&#39;train&#39;),(&#39;foot&#39;,&#39;test&#39;)
        transform: A function that takes data and label and transforms them. 
                    A transform function for object detection should take label into consideration,
                    because any geometric modification will require label to be modified.
        index_map: In default, the 20 classes are mapped into indices from 0 to 19.
                    We can customize it by providing a str to int dict specifying how to map class names to indices.
                    Use by advanced users only, when you want to swap the orders of class labels.
        preload_label: If True, then parse and load all labels into memory during initialization.
                        It often accelerate speed but require more memory usage.
                        Typical preloaded labels took tens of MB.
                        You only need to disable it when your dataset is extremely large.
    &#34;&#34;&#34;

    def __init__(
        self, root, splits, transform=None, index_map=None, preload_label=True
    ):

        super(VOCFootball, self).__init__(
            root, splits, transform, index_map, preload_label
        )


def get_dataloader(
    net, train_dataset, val_dataset, data_shape, batch_size, num_workers, ctx
):
    &#34;&#34;&#34;Loads data from a dataset and returns mini-batches of data, for both the training
    and the validation set.

    Arguments:
        net: the Gluon model you will train, used to generate fake anchors for target generation.
        train_dataset: Training dataset. Note that numpy and mxnet arrays can be directly used as a Dataset.
        val_dataset: Validation dataset. Note that numpy and mxnet arrays can be directly used as a Dataset.
        data_shape: Tuple, the input_shape of the model
        batch_size: Size of mini-batch.
        num_workers: The number of multiprocessing workers to use for data preprocessing.
        ctx: Indicator to the usage of GPU.
    Returns:
        train_loader: Gluon training dataloader
        val_loader: Gluon testing dataloader
    Raises:

    &#34;&#34;&#34;
    width, height = data_shape

    # use fake data to generate fixed anchors for target generation
    with autograd.train_mode():
        _, _, anchors = net(mx.nd.zeros((1, 3, height, width), ctx))

    anchors = anchors.as_in_context(mx.cpu())

    batchify_fn = Tuple(
        Stack(), Stack(), Stack()
    )  # stack image, cls_targets, box_targets

    train_loader = gluon.data.DataLoader(
        train_dataset.transform(SSDDefaultTrainTransform(width, height, anchors)),
        batch_size,
        True,
        batchify_fn=batchify_fn,
        last_batch=&#34;rollover&#34;,
        num_workers=num_workers,
    )

    val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))

    val_loader = gluon.data.DataLoader(
        val_dataset.transform(SSDDefaultValTransform(width, height)),
        batch_size,
        False,
        batchify_fn=val_batchify_fn,
        last_batch=&#34;keep&#34;,
        num_workers=num_workers,
    )

    return train_loader, val_loader


class TrackingDatasetBuilder:
    &#34;&#34;&#34;Class for an homography dataset. Allows to load pairs of image, homography, and
    apply random transformation to them. Also loads the dataloader you can then pass to a keras model.

    Arguments:
        dataset_path: Path to folder storing the dataset
        batch_size: Size of mini-batch.
        input_shape: Tuple, the input_shape of the model
        net: the Gluon model you will train, used to generate fake anchors for target generation.
        train_splits: List of tuples, list of combinations (type,name) for training
        test_splits: List of tuples, list of combinations (type,name) for testing
        num_workers: The number of multiprocessing workers to use for data preprocessing.
        
    &#34;&#34;&#34;

    def __init__(
        self,
        dataset_path,
        batch_size,
        input_shape,
        net,
        train_splits=[(&#34;foot&#34;, &#34;train&#34;), (&#34;foot&#34;, &#34;val&#34;)],
        test_splits=[(&#34;foot&#34;, &#34;test&#34;)],
        num_workers=1,
    ):

        self.train_dataset = VOCFootball(root=dataset_path, splits=train_splits)

        self.valid_dataset = VOCFootball(root=dataset_path, splits=test_splits)

        train_loader, val_loader = get_dataloader(
            net,
            self.train_dataset,
            self.valid_dataset,
            input_shape,
            batch_size,
            num_workers,
            ctx,
        )

        self.train_dataloader = train_loader
        self.valid_dataloader = val_loader

    def _get_dataset(self):
        return self.train_dataset, self.valid_dataset

    def _get_dataloader(self):
        return self.train_dataloader, self.valid_dataloader</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="narya.datasets.tracking_dataset.CLASSES"><code class="name">var <span class="ident">CLASSES</span></code></dt>
<dd>
<div class="desc"><p>Checking with Mxnet if a GPU is available or not.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="narya.datasets.tracking_dataset.get_dataloader"><code class="name flex">
<span>def <span class="ident">get_dataloader</span></span>(<span>net, train_dataset, val_dataset, data_shape, batch_size, num_workers, ctx)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads data from a dataset and returns mini-batches of data, for both the training
and the validation set.</p>
<h2 id="arguments">Arguments</h2>
<p>net: the Gluon model you will train, used to generate fake anchors for target generation.
train_dataset: Training dataset. Note that numpy and mxnet arrays can be directly used as a Dataset.
val_dataset: Validation dataset. Note that numpy and mxnet arrays can be directly used as a Dataset.
data_shape: Tuple, the input_shape of the model
batch_size: Size of mini-batch.
num_workers: The number of multiprocessing workers to use for data preprocessing.
ctx: Indicator to the usage of GPU.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>train_loader</code></dt>
<dd>Gluon training dataloader</dd>
<dt><code>val_loader</code></dt>
<dd>Gluon testing dataloader</dd>
</dl>
<p>Raises:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_dataloader(
    net, train_dataset, val_dataset, data_shape, batch_size, num_workers, ctx
):
    &#34;&#34;&#34;Loads data from a dataset and returns mini-batches of data, for both the training
    and the validation set.

    Arguments:
        net: the Gluon model you will train, used to generate fake anchors for target generation.
        train_dataset: Training dataset. Note that numpy and mxnet arrays can be directly used as a Dataset.
        val_dataset: Validation dataset. Note that numpy and mxnet arrays can be directly used as a Dataset.
        data_shape: Tuple, the input_shape of the model
        batch_size: Size of mini-batch.
        num_workers: The number of multiprocessing workers to use for data preprocessing.
        ctx: Indicator to the usage of GPU.
    Returns:
        train_loader: Gluon training dataloader
        val_loader: Gluon testing dataloader
    Raises:

    &#34;&#34;&#34;
    width, height = data_shape

    # use fake data to generate fixed anchors for target generation
    with autograd.train_mode():
        _, _, anchors = net(mx.nd.zeros((1, 3, height, width), ctx))

    anchors = anchors.as_in_context(mx.cpu())

    batchify_fn = Tuple(
        Stack(), Stack(), Stack()
    )  # stack image, cls_targets, box_targets

    train_loader = gluon.data.DataLoader(
        train_dataset.transform(SSDDefaultTrainTransform(width, height, anchors)),
        batch_size,
        True,
        batchify_fn=batchify_fn,
        last_batch=&#34;rollover&#34;,
        num_workers=num_workers,
    )

    val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))

    val_loader = gluon.data.DataLoader(
        val_dataset.transform(SSDDefaultValTransform(width, height)),
        batch_size,
        False,
        batchify_fn=val_batchify_fn,
        last_batch=&#34;keep&#34;,
        num_workers=num_workers,
    )

    return train_loader, val_loader</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="narya.datasets.tracking_dataset.TrackingDatasetBuilder"><code class="flex name class">
<span>class <span class="ident">TrackingDatasetBuilder</span></span>
<span>(</span><span>dataset_path, batch_size, input_shape, net, train_splits=[('foot', 'train'), ('foot', 'val')], test_splits=[('foot', 'test')], num_workers=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for an homography dataset. Allows to load pairs of image, homography, and
apply random transformation to them. Also loads the dataloader you can then pass to a keras model.</p>
<h2 id="arguments">Arguments</h2>
<p>dataset_path: Path to folder storing the dataset
batch_size: Size of mini-batch.
input_shape: Tuple, the input_shape of the model
net: the Gluon model you will train, used to generate fake anchors for target generation.
train_splits: List of tuples, list of combinations (type,name) for training
test_splits: List of tuples, list of combinations (type,name) for testing
num_workers: The number of multiprocessing workers to use for data preprocessing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TrackingDatasetBuilder:
    &#34;&#34;&#34;Class for an homography dataset. Allows to load pairs of image, homography, and
    apply random transformation to them. Also loads the dataloader you can then pass to a keras model.

    Arguments:
        dataset_path: Path to folder storing the dataset
        batch_size: Size of mini-batch.
        input_shape: Tuple, the input_shape of the model
        net: the Gluon model you will train, used to generate fake anchors for target generation.
        train_splits: List of tuples, list of combinations (type,name) for training
        test_splits: List of tuples, list of combinations (type,name) for testing
        num_workers: The number of multiprocessing workers to use for data preprocessing.
        
    &#34;&#34;&#34;

    def __init__(
        self,
        dataset_path,
        batch_size,
        input_shape,
        net,
        train_splits=[(&#34;foot&#34;, &#34;train&#34;), (&#34;foot&#34;, &#34;val&#34;)],
        test_splits=[(&#34;foot&#34;, &#34;test&#34;)],
        num_workers=1,
    ):

        self.train_dataset = VOCFootball(root=dataset_path, splits=train_splits)

        self.valid_dataset = VOCFootball(root=dataset_path, splits=test_splits)

        train_loader, val_loader = get_dataloader(
            net,
            self.train_dataset,
            self.valid_dataset,
            input_shape,
            batch_size,
            num_workers,
            ctx,
        )

        self.train_dataloader = train_loader
        self.valid_dataloader = val_loader

    def _get_dataset(self):
        return self.train_dataset, self.valid_dataset

    def _get_dataloader(self):
        return self.train_dataloader, self.valid_dataloader</code></pre>
</details>
</dd>
<dt id="narya.datasets.tracking_dataset.VOCFootball"><code class="flex name class">
<span>class <span class="ident">VOCFootball</span></span>
<span>(</span><span>root, splits, transform=None, index_map=None, preload_label=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for a tracking dataset. Allows to load pairs of image, bouding boxes, and
apply random transformation to them. The dataset is base on the gluoncv.data VOC format
dataset. You can also easily write your own custom dataset if your data are in a COCO format.</p>
<h2 id="arguments">Arguments</h2>
<p>root: Path to folder storing the dataset
splits: List of tuples, list of combinations (type,name). e.g: ('foot','train'),('foot','test')
transform: A function that takes data and label and transforms them.
A transform function for object detection should take label into consideration,
because any geometric modification will require label to be modified.
index_map: In default, the 20 classes are mapped into indices from 0 to 19.
We can customize it by providing a str to int dict specifying how to map class names to indices.
Use by advanced users only, when you want to swap the orders of class labels.
preload_label: If True, then parse and load all labels into memory during initialization.
It often accelerate speed but require more memory usage.
Typical preloaded labels took tens of MB.
You only need to disable it when your dataset is extremely large.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VOCFootball(VOCDetection):
    &#34;&#34;&#34;Class for a tracking dataset. Allows to load pairs of image, bouding boxes, and
    apply random transformation to them. The dataset is base on the gluoncv.data VOC format
    dataset. You can also easily write your own custom dataset if your data are in a COCO format.

    Arguments:
        root: Path to folder storing the dataset
        splits: List of tuples, list of combinations (type,name). e.g: (&#39;foot&#39;,&#39;train&#39;),(&#39;foot&#39;,&#39;test&#39;)
        transform: A function that takes data and label and transforms them. 
                    A transform function for object detection should take label into consideration,
                    because any geometric modification will require label to be modified.
        index_map: In default, the 20 classes are mapped into indices from 0 to 19.
                    We can customize it by providing a str to int dict specifying how to map class names to indices.
                    Use by advanced users only, when you want to swap the orders of class labels.
        preload_label: If True, then parse and load all labels into memory during initialization.
                        It often accelerate speed but require more memory usage.
                        Typical preloaded labels took tens of MB.
                        You only need to disable it when your dataset is extremely large.
    &#34;&#34;&#34;

    def __init__(
        self, root, splits, transform=None, index_map=None, preload_label=True
    ):

        super(VOCFootball, self).__init__(
            root, splits, transform, index_map, preload_label
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>gluoncv.data.pascal_voc.detection.VOCDetection</li>
<li>gluoncv.data.base.VisionDataset</li>
<li>mxnet.gluon.data.dataset.Dataset</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="narya.datasets" href="index.html">narya.datasets</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="narya.datasets.tracking_dataset.CLASSES" href="#narya.datasets.tracking_dataset.CLASSES">CLASSES</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="narya.datasets.tracking_dataset.get_dataloader" href="#narya.datasets.tracking_dataset.get_dataloader">get_dataloader</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="narya.datasets.tracking_dataset.TrackingDatasetBuilder" href="#narya.datasets.tracking_dataset.TrackingDatasetBuilder">TrackingDatasetBuilder</a></code></h4>
</li>
<li>
<h4><code><a title="narya.datasets.tracking_dataset.VOCFootball" href="#narya.datasets.tracking_dataset.VOCFootball">VOCFootball</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>